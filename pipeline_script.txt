#!/bin/bash

# defining file paths as variables for simpler use later in the script
fastqdir=/localdisk/data/BPSM/AY21/fastq
Tcongo_genome=/localdisk/data/BPSM/AY21/Tcongo_genome/TriTrypDB-46_TcongolenseIL3000_2019_Genome.fasta.gz
bedfile=/localdisk/data/BPSM/AY21/TriTrypDB-46_TcongolenseIL3000_2019.bed

mkdir fastqc_outputs
for fastq_file in $fastqdir/*fq.gz
 do
 fastqc -o fastqc_outputs $fastq_file 
done

# assessing quality of output data. NEED TO DO NUMBERS AS WELL?!
for fastqc_file in fastqc_outputs/*.zip
 do
 echo -e "\nSee below for summary statistics and fastqc quality metrics that sample ${fastqc_file:15:-11} failed on or where there are warnings."
 echo "Please see the full html report including plots at ${fastqc_file::-4}.html"
 echo -e "If quality is deemed to be insufficient please use the program Trimmomatic to filter poor quality reads and trim poor quality bases."
 echo -e "Please save any trimmed fastq files in the same location with the same name as the original fastq file to overwrite it.\n"
 unzip -q $fastqc_file 
 head ${fastqc_file:15:-4}/fastqc_data.txt
 echo ""
 cat ${fastqc_file:15:-4}/summary.txt | grep "FAIL\|WARN"
done
 

# create bowtie2 index database for the T. congolense reference genome
#bowtie2-build $Tcongo_genome Tcongo_indexed_genome

# iterate over all pairs of fastq files
for fastq_1_file in $fastqdir/*1.fq.gz
do
fastq_2_file=`echo $fastq_1_file | sed 's/_1/_2/'`

# map each pair of reads to the bowtie index database for the T. congolense reference genome 
#bowtie2 -x Tcongo_indexed_genome -q -1 $fastq_1_file -2 $fastq_2_file -S ${fastq_1_file:32:-8}.sam

# convert sam file from bowtie2 output to a bam file
#samtools view -b -S ${fastq_1_file:32:-8}.sam > ${fastq_1_file:32:-8}.bam
#samtools sort ${fastq_1_file:32:-8}.bam -o ${fastq_1_file:32:-8}.sorted.bam
#samtools index ${fastq_1_file:32:-8}.sorted.bam

# count the reads using bedtools multicov. -D means includes duplicate reads
#bedtools multicov -D -bams ${fastq_1_file:32:-8}.sorted.bam -bed $bedfile > ${fastq_1_file:32:-8}.counts

done

# Now need to generate groups from the sample info file.

# Removing old groups 
rm *group.txt
IFS=$'\t'
while read id sample replicate time treatment end1 end2
do
if test $sample == "Clone1" && test $time == "0" 
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> clone1_0_group.txt
fi
if test $sample == Clone2 && test $time == 0 
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> clone2_0_group.txt
fi
if test $sample == WT && test $time == 0 
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> wt_0_group.txt
fi
if test $sample == Clone1 && test $time == 24 && test $treatment == Uninduced
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> clone1_24_unind_group.txt
fi
if test $sample == Clone2 && test $time == 24 && test $treatment == Uninduced
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> clone2_24_unind_group.txt
fi
if test $sample == WT && test $time == 24 && test $treatment == Uninduced
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> wt_24_unind_group.txt
fi
if test $sample == Clone1 && test $time == 48 && test $treatment == Uninduced
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> clone1_48_unind_group.txt
fi
if test $sample == Clone2 && test $time == 48 && test $treatment == Uninduced
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> clone2_48_unind_group.txt
fi
if test $sample == WT && test $time == 48 && test $treatment == Uninduced
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> wt_48_unind_group.txt
fi
if test $sample == Clone1 && test $time == 24 && test $treatment == Induced
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> clone1_24_ind_group.txt
fi
if test $sample == Clone2 && test $time == 24 && test $treatment == Induced
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> clone2_24_ind_group.txt
fi
if test $sample == WT && test $time == 24 && test $treatment == Induced
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> wt_24_ind_group.txt
fi
if test $sample == Clone1 && test $time == 48 && test $treatment == Induced
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> clone1_48_ind_group.txt
fi
if test $sample == Clone2 && test $time == 48 && test $treatment == Induced
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> clone2_48_ind_group.txt
fi
if test $sample == WT && test $time == 48 && test $treatment == Induced
then echo -e "$id\t$sample\t$replicate\t$time\t$treatment\t$end1\t$end2" >> wt_48_ind_group.txt
fi
done < "/localdisk/data/BPSM/AY21/fastq/100k.fqfiles" 

# aim to create bedtools multicov outputs for all groups
# looping over all the 15 groups
for group_file in clone2_24_unind_group.txt
 do
 echo $group_file
 bam_file_array=()
 sample_count=0
 sample_count_array=()
 while read id sample replicate time treatment end1 end2
 do
 # add the bam files for the samples in the group to an array
 for bam_file in *.sorted.bam
  do
  if test ${end1::13} == ${bam_file::13}
   then
   bam_file_array+=($bam_file)
   sample_count=$((sample_count+1))
   sample_count_array+=("r$sample_count")
  fi
 done
 done < $group_file

 echo ${sample_count_array[*]}
 echo ${bam_file_array[*]}

# use the array as input to the bedtools multicov. Sample reads will appear in columns in the same file making determining their mean much easier.
#bedtools multicov -bams ${bam_file_array[*]} -bed $bedfile > ${group_file::-4}.counts.tsv

# find the mean of the read data for the groups and paste these into a new file with just the gene names and descriptions
 while read f1 f2 f3 gene_name gene_description ${sample_count_array[*]}
 do 
 total=0
 for i in ${sample_count_array[@]} 
  do
  total=$(($total+$i))
 done
 mean=$(($total/${#sample_count_array[@]}))
 echo -e "$gene_name\t$gene_description\t$mean" >> clone2_24_unind_group.mean.counts.tsv
 done < clone2_24_unind_group.counts.tsv 
done
